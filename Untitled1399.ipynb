{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92c62908-c1c2-4d2c-bdff-085fe214f009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] Could not auto-derive labels.\n",
      "\n",
      "Preview (first 8 rows):\n",
      " ID       Audio basename\n",
      "  1 audio/1.wav        1\n",
      "  2 audio/2.wav        2\n",
      "  3 audio/3.wav        3\n",
      "  4 audio/4.wav        4\n",
      "  5 audio/5.wav        5\n",
      "\n",
      "Try to rename files or add a label column to CSV, OR tell me the pattern in your filenames and I’ll craft a regex.\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, glob, argparse\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa, soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# -------- Defaults --------\n",
    "DEFAULT_AUDIO_DIR = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\"\n",
    "DEFAULT_TEXT_DIR  = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\text\"\n",
    "DEFAULT_CSV_PATH  = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\British English Speech Recognition.csv\"\n",
    "DEFAULT_OUT_DIR   = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\"\n",
    "\n",
    "POSSIBLE_TEXT_COLS = [\"transcript\",\"Transcript\",\"text\",\"Text\",\"utterance\",\"sentence\",\"phrase\"]\n",
    "\n",
    "# ----------------- Helpers -----------------\n",
    "def list_basenames(root, exts):\n",
    "    out = {}\n",
    "    for pat in exts:\n",
    "        for path in glob.glob(os.path.join(root, pat)):\n",
    "            out[os.path.splitext(os.path.basename(path))[0]] = path\n",
    "    return out\n",
    "\n",
    "def read_csv_any(path):\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, encoding=\"latin-1\")\n",
    "\n",
    "def robust_load_wav(path, sr=16000):\n",
    "    try:\n",
    "        y, r = sf.read(path, always_2d=False)\n",
    "        if isinstance(y, np.ndarray):\n",
    "            if y.ndim > 1: y = np.mean(y, axis=1)\n",
    "            if r != sr:\n",
    "                y = librosa.resample(y.astype(float), orig_sr=r, target_sr=sr); r = sr\n",
    "        return y.astype(float), r\n",
    "    except Exception:\n",
    "        try:\n",
    "            y, r = librosa.load(path, sr=sr, mono=True); return y, r\n",
    "        except Exception:\n",
    "            return None, None\n",
    "\n",
    "# ----------------- Pickle-safe transformers -----------------\n",
    "class Squeeze1D(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return np.asarray(X, dtype=object).ravel()\n",
    "\n",
    "class TextStatExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_ = np.array([\"char_len\",\"word_count\",\"avg_word_len\"]); return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=object).ravel().tolist()\n",
    "        rows = []\n",
    "        for t in X:\n",
    "            t = t if isinstance(t, str) else \"\"\n",
    "            words = re.findall(r\"\\w+\", t, flags=re.UNICODE)\n",
    "            rows.append([len(t), len(words), (sum(len(w) for w in words)/len(words) if words else 0.0)])\n",
    "        return np.array(rows, dtype=float)\n",
    "\n",
    "class AudioFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sr=16000, n_mfcc=13): self.sr=sr; self.n_mfcc=n_mfcc\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=object).ravel().tolist(); feats=[]\n",
    "        for p in X: feats.append(self._feat_one(p))\n",
    "        return np.array(feats)\n",
    "    def _feat_one(self, path):\n",
    "        try:\n",
    "            y, sr = robust_load_wav(path, sr=self.sr)\n",
    "            if y is None or len(y)==0: raise RuntimeError\n",
    "            dur = len(y)/float(sr)\n",
    "            rms = librosa.feature.rms(y=y).flatten()\n",
    "            zcr = librosa.feature.zero_crossing_rate(y).flatten()\n",
    "            sc  = librosa.feature.spectral_centroid(y=y, sr=sr).flatten()\n",
    "            mf  = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
    "            v = [\n",
    "                dur,\n",
    "                float(np.mean(rms)) if rms.size else 0.0,\n",
    "                float(np.std(rms))  if rms.size else 0.0,\n",
    "                float(np.mean(zcr)) if zcr.size else 0.0,\n",
    "                float(np.mean(sc))  if sc.size else 0.0,\n",
    "                float(np.std(sc))   if sc.size else 0.0,\n",
    "            ]\n",
    "            if mf.size:\n",
    "                v += list(np.mean(mf, axis=1)); v += list(np.std(mf, axis=1))\n",
    "            else:\n",
    "                v += [0.0]*self.n_mfcc + [0.0]*self.n_mfcc\n",
    "            return v\n",
    "        except Exception:\n",
    "            return [0.0]*(6 + self.n_mfcc*2)\n",
    "\n",
    "# ----------------- Auto label derivation -----------------\n",
    "def try_regex(series, patterns):\n",
    "    \"\"\"Return first successful extracted series (>=2 unique, notna count >=2) and the pattern used.\"\"\"\n",
    "    for regex in patterns:\n",
    "        pat = re.compile(regex)\n",
    "        ext = series.astype(str).apply(lambda s: (pat.search(s).group(1) if pat.search(s) else None))\n",
    "        if ext.notna().sum() >= 2 and ext.dropna().nunique() >= 2:\n",
    "            return ext, regex\n",
    "    return None, None\n",
    "\n",
    "def derive_labels(df):\n",
    "    \"\"\"\n",
    "    Auto-derive a categorical label series using, in order:\n",
    "      A) parent folder of Audio/basename\n",
    "      B) prefix before _ or -\n",
    "      C) suffix letters before trailing digits\n",
    "      D) ID pattern like spk_en_001\n",
    "    Returns (label_series, source_hint)\n",
    "    \"\"\"\n",
    "    # Candidate text sources to parse from\n",
    "    src_cols = []\n",
    "    if \"Audio\" in df.columns: src_cols.append(\"Audio\")\n",
    "    if \"basename\" in df.columns: src_cols.append(\"basename\")\n",
    "    if \"ID\" in df.columns: src_cols.append(\"ID\")\n",
    "\n",
    "    # A) parent folder name\n",
    "    folder_patterns = [\n",
    "        r\".*[/\\\\]([A-Za-z]+)[/\\\\][^/\\\\]+$\",      # ...\\en\\clip.wav -> en\n",
    "        r\"^([A-Za-z]{2,})[/\\\\][^/\\\\]+$\",         # en\\clip.wav (if basename kept path-like)\n",
    "    ]\n",
    "    # B) filename prefix\n",
    "    prefix_patterns = [\n",
    "        r\"^([A-Za-z]{2,})[_-]\",                  # en_0001.wav  / en-0001.wav\n",
    "        r\"^([A-Za-z]{2,})\\d\",                    # en123.wav\n",
    "    ]\n",
    "    # C) filename suffix letters before numbers\n",
    "    suffix_patterns = [\n",
    "        r\"_([A-Za-z]{2,})\\d*\\.[A-Za-z0-9]+$\",    # sample_en123.wav\n",
    "        r\"-([A-Za-z]{2,})\\d*\\.[A-Za-z0-9]+$\",\n",
    "    ]\n",
    "    # D) ID-style\n",
    "    id_patterns = [\n",
    "        r\"^spk_([A-Za-z]{2,})_\",                 # spk_en_001\n",
    "        r\".*[_-]([A-Za-z]{2,})[_-]\\d+\",          # abc_en_001\n",
    "        r\".*[_-]([A-Za-z]{2,})$\",                # abc-en\n",
    "    ]\n",
    "\n",
    "    # Try Audio/basename for A/B/C\n",
    "    for col in [c for c in [\"Audio\",\"basename\"] if c in src_cols]:\n",
    "        s = df[col].astype(str)\n",
    "        for pats, tag in [(folder_patterns,\"folder\"), (prefix_patterns,\"prefix\"), (suffix_patterns,\"suffix\")]:\n",
    "            out, used = try_regex(s, pats)\n",
    "            if out is not None:\n",
    "                return out, f\"{col}:{tag}:{used}\"\n",
    "\n",
    "    # Try ID\n",
    "    if \"ID\" in src_cols:\n",
    "        out, used = try_regex(df[\"ID\"].astype(str), id_patterns)\n",
    "        if out is not None:\n",
    "            return out, f\"ID:pattern:{used}\"\n",
    "\n",
    "    # Give up\n",
    "    return None, None\n",
    "\n",
    "# ----------------- Main -----------------\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"PolyGlotAI accuracy + heatmap (AUTO labels)\")\n",
    "    ap.add_argument(\"--audio\", default=DEFAULT_AUDIO_DIR)\n",
    "    ap.add_argument(\"--text\",  default=DEFAULT_TEXT_DIR)\n",
    "    ap.add_argument(\"--csv\",   default=DEFAULT_CSV_PATH)\n",
    "    ap.add_argument(\"--out\",   default=DEFAULT_OUT_DIR)\n",
    "    args, _ = ap.parse_known_args()\n",
    "\n",
    "    os.makedirs(args.out, exist_ok=True)\n",
    "\n",
    "    # Collect maps (not strictly needed but kept for completeness)\n",
    "    audio_map = list_basenames(args.audio, (\"*.wav\",\"*.WAV\"))\n",
    "    text_map  = list_basenames(args.text,  (\"*.txt\",\"*.TXT\"))\n",
    "\n",
    "    # CSV\n",
    "    df_csv = read_csv_any(args.csv) if os.path.isfile(args.csv) else pd.DataFrame()\n",
    "    if not df_csv.empty:\n",
    "        fname_col = next((c for c in [\"filename\",\"file\",\"path\",\"wav\",\"audio\",\"fname\",\"id\",\"ID\",\"Name\",\"name\",\"Audio\"] if c in df_csv.columns), None)\n",
    "        if fname_col:\n",
    "            df_csv[\"basename\"] = df_csv[fname_col].astype(str).apply(lambda p: os.path.splitext(os.path.basename(p))[0])\n",
    "        else:\n",
    "            df_csv[\"basename\"] = df_csv.index.astype(str)\n",
    "        text_col = next((c for c in POSSIBLE_TEXT_COLS if c in df_csv.columns), None)\n",
    "    else:\n",
    "        union = sorted(set(audio_map.keys()) | set(text_map.keys()))\n",
    "        df_csv = pd.DataFrame({\"basename\": union}); text_col = None\n",
    "\n",
    "    # Attach paths + text\n",
    "    df_csv[\"audio_path\"] = df_csv[\"basename\"].map(audio_map)\n",
    "    df_csv[\"text_value\"] = df_csv[text_col].fillna(\"\").astype(str) if text_col else \"\"\n",
    "    def fill_txt(row):\n",
    "        if isinstance(row[\"text_value\"], str) and row[\"text_value\"]:\n",
    "            return row[\"text_value\"]\n",
    "        p = text_map.get(row[\"basename\"])\n",
    "        if p and os.path.isfile(p):\n",
    "            try: return open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\").read().strip()\n",
    "            except Exception: return \"\"\n",
    "        return \"\"\n",
    "    df_csv[\"text_value\"] = df_csv.apply(fill_txt, axis=1)\n",
    "\n",
    "    # keep rows that have audio (optional—just ensuring alignment)\n",
    "    df = df_csv[df_csv[\"audio_path\"].notna()].reset_index(drop=True)\n",
    "\n",
    "    # ------- AUTO label --------\n",
    "    label_series, hint = derive_labels(df)\n",
    "    if label_series is None or label_series.dropna().nunique() < 2:\n",
    "        print(\"[WARN] Could not auto-derive labels.\")\n",
    "        # Show a preview to help you see patterns:\n",
    "        print(\"\\nPreview (first 8 rows):\")\n",
    "        cols_to_show = [c for c in [\"ID\",\"Audio\",\"basename\"] if c in df.columns]\n",
    "        print(df[cols_to_show].head(8).to_string(index=False))\n",
    "        print(\"\\nTry to rename files or add a label column to CSV, OR tell me the pattern in your filenames and I’ll craft a regex.\")\n",
    "        return\n",
    "\n",
    "    df[\"__auto_label\"] = label_series.fillna(\"unknown\")\n",
    "    # ensure at least 2 classes after filling\n",
    "    if df[\"__auto_label\"].nunique() < 2:\n",
    "        print(\"[WARN] Auto labels collapsed to a single class after fill; need >=2.\")\n",
    "        return\n",
    "\n",
    "    print(f\"[INFO] Labels derived via: {hint}\")\n",
    "    # map strings to integers\n",
    "    cats = {v: i for i, v in enumerate(sorted(df[\"__auto_label\"].unique()))}\n",
    "    y = df[\"__auto_label\"].map(cats)\n",
    "\n",
    "    # ------------------ Features ------------------\n",
    "    X_frame = pd.DataFrame({\n",
    "        \"audio_path\": df[\"audio_path\"].astype(str).values,\n",
    "        \"text_value\": df[\"text_value\"].astype(str).values\n",
    "    })\n",
    "\n",
    "    audio_pipe = Pipeline([\n",
    "        (\"sel\", Squeeze1D()),\n",
    "        (\"afe\", AudioFeatureExtractor(sr=16000, n_mfcc=13)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    text_stats = TextStatExtractor()\n",
    "    text_tfidf = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,4), max_features=800)\n",
    "    text_features = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf\", Pipeline([(\"sel\", Squeeze1D()), (\"tfidf\", text_tfidf)]), \"text_value\"),\n",
    "            (\"tstats\", Pipeline([(\"sel\", Squeeze1D()), (\"tstat\", text_stats)]), \"text_value\"),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    full_feat = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"audio\", audio_pipe, [\"audio_path\"]),\n",
    "            (\"text\",  text_features, [\"text_value\"])\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    # ------------------ Train/test ------------------\n",
    "    if pd.Series(y).nunique() < 2:\n",
    "        print(\"[WARN] Need at least 2 classes to compute accuracy/heatmap.\")\n",
    "        return\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_frame, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=2000),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "    }\n",
    "\n",
    "    metrics = {}\n",
    "    best_name, best_score, best_pipe = None, -np.inf, None\n",
    "\n",
    "    for name, est in models.items():\n",
    "        pipe = Pipeline([(\"features\", full_feat), (\"model\", est)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        auc = None\n",
    "        try:\n",
    "            if len(np.unique(y_test)) == 2 and hasattr(pipe, \"predict_proba\"):\n",
    "                probs = pipe.predict_proba(X_test)[:, 1]\n",
    "                if not np.allclose(np.min(probs), np.max(probs)):\n",
    "                    auc = roc_auc_score(y_test, probs)\n",
    "        except Exception:\n",
    "            auc = None\n",
    "\n",
    "        chosen = auc if auc is not None else acc\n",
    "        metrics[name] = {\"accuracy\": float(acc), \"roc_auc\": (None if auc is None else float(auc)), \"chosen_score\": float(chosen)}\n",
    "        if chosen > best_score:\n",
    "            best_score, best_name, best_pipe = chosen, name, pipe\n",
    "\n",
    "    # ------------------ Accuracy bar chart ------------------\n",
    "    os.makedirs(args.out, exist_ok=True)\n",
    "    acc_path = os.path.join(args.out, \"polyglot_accuracy.png\")\n",
    "    names = list(metrics.keys()); accs = [metrics[k][\"accuracy\"] for k in names]\n",
    "    plt.figure(figsize=(7,5), dpi=140)\n",
    "    bars = plt.bar(names, accs)\n",
    "    plt.title(\"Model Accuracy (Test Set)\")\n",
    "    plt.ylabel(\"Accuracy\"); plt.ylim(0, 1.0)\n",
    "    for b, v in zip(bars, accs):\n",
    "        plt.text(b.get_x()+b.get_width()/2, v+0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.tight_layout(); plt.savefig(acc_path); plt.show()\n",
    "\n",
    "    # ------------------ Confusion matrix heatmap ------------------\n",
    "    y_pred_best = best_pipe.predict(X_test)\n",
    "    labels_sorted = np.unique(np.concatenate([y_test, y_pred_best]))\n",
    "    cm = confusion_matrix(y_test, y_pred_best, labels=labels_sorted)\n",
    "\n",
    "    heat_path = os.path.join(args.out, \"polyglot_confusion_heatmap.png\")\n",
    "    plt.figure(figsize=(6,5), dpi=140)\n",
    "    im = plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(f\"Confusion Matrix (Best: {best_name})\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(labels_sorted))\n",
    "    plt.xticks(ticks, labels_sorted); plt.yticks(ticks, labels_sorted)\n",
    "    plt.xlabel(\"Predicted\"); plt.ylabel(\"Actual\")\n",
    "    thresh = cm.max()/2.0 if cm.size else 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout(); plt.savefig(heat_path); plt.show()\n",
    "\n",
    "    # ------------------ Save metrics ------------------\n",
    "    metrics_path = os.path.join(args.out, \"polyglot_metrics.json\")\n",
    "    out_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"audio_dir\": args.audio, \"text_dir\": args.text, \"csv_path\": args.csv,\n",
    "        \"label_derivation\": hint,\n",
    "        \"models\": metrics, \"best_model\": best_name,\n",
    "        \"class_mapping\": {k:int(v) for k,v in {k:v for k,v in zip(sorted(df['__auto_label'].unique()), range(len(sorted(df['__auto_label'].unique()))))}.items()},\n",
    "        \"labels_used_sorted\": [int(x) if isinstance(x, (np.integer,)) else (x.item() if isinstance(x, np.generic) else x) for x in labels_sorted]\n",
    "    }\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out_metrics, f, indent=2)\n",
    "\n",
    "    print(\"\\n=== Saved ===\")\n",
    "    print(\"Accuracy chart ->\", acc_path)\n",
    "    print(\"Heatmap        ->\", heat_path)\n",
    "    print(\"Metrics JSON   ->\", metrics_path)\n",
    "    print(\"Label hint     ->\", hint)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a4185-0ddb-49ec-84b9-85f455a9338b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
