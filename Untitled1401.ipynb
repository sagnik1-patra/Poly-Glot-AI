{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8645a485-edaf-468d-8819-8ea51fa3e208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Prediction complete ===\n",
      "Predictions CSV -> C:\\Users\\sagni\\Downloads\\Poly Glot AI\\polyglot_predictions.csv\n",
      "Summary JSON    -> C:\\Users\\sagni\\Downloads\\Poly Glot AI\\polyglot_summary.json\n",
      "Head:\n",
      " ID       Audio       Text basename                                                audio_path text_value  prediction\n",
      "  1 audio/1.wav text/1.txt        1 C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\\1.wav text/1.txt           0\n",
      "  2 audio/2.wav text/2.txt        2 C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\\2.wav text/2.txt           1\n",
      "  3 audio/3.wav text/3.txt        3 C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\\3.wav text/3.txt           3\n",
      "  4 audio/4.wav text/4.txt        4 C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\\4.wav text/4.txt           2\n",
      "  5 audio/5.wav text/5.txt        5 C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\\5.wav text/5.txt           4\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, glob, argparse, sys, types\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import librosa, soundfile as sf\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# ---------- Defaults ----------\n",
    "DEFAULT_MODEL = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\polyglot_model.pkl\"\n",
    "DEFAULT_AUDIO_DIR = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\"\n",
    "DEFAULT_TEXT_DIR  = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\text\"\n",
    "DEFAULT_CSV_PATH  = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\British English Speech Recognition.csv\"\n",
    "DEFAULT_OUT_DIR   = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\"\n",
    "POSSIBLE_TEXT_COLS = [\"Text\",\"text\",\"Transcript\",\"transcript\",\"utterance\",\"sentence\",\"phrase\"]\n",
    "\n",
    "# ---------- Robust I/O helpers ----------\n",
    "def list_basenames(root, exts=(\"*.wav\",\"*.WAV\")):\n",
    "    out = {}\n",
    "    for pat in exts:\n",
    "        for path in glob.glob(os.path.join(root, pat)):\n",
    "            out[os.path.splitext(os.path.basename(path))[0]] = path\n",
    "    return out\n",
    "\n",
    "def try_read_csv(path):\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, encoding=\"latin-1\")\n",
    "\n",
    "def safe_read_txt(path):\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return f.read().strip()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "def robust_load_wav(path, sr=16000):\n",
    "    try:\n",
    "        y, r = sf.read(path, always_2d=False)\n",
    "        if isinstance(y, np.ndarray):\n",
    "            if y.ndim > 1:\n",
    "                y = np.mean(y, axis=1)\n",
    "            if r != sr:\n",
    "                y = librosa.resample(y.astype(float), orig_sr=r, target_sr=sr)\n",
    "                r = sr\n",
    "        return y.astype(float), r\n",
    "    except Exception:\n",
    "        try:\n",
    "            y, r = librosa.load(path, sr=sr, mono=True)\n",
    "            return y, r\n",
    "        except Exception:\n",
    "            return None, None\n",
    "\n",
    "# ---------- Re-register custom classes so unpickling works ----------\n",
    "# The model was pickled with custom transformers (Squeeze1D, TextStatExtractor, AudioFeatureExtractor)\n",
    "# likely under module 'polyglot_train_and_export'. We create a dummy module of that name and\n",
    "# register identical classes into it so joblib.load can resolve them.\n",
    "poly_mod_name = \"polyglot_train_and_export\"\n",
    "poly_mod = types.ModuleType(poly_mod_name)\n",
    "sys.modules[poly_mod_name] = poly_mod\n",
    "\n",
    "class Squeeze1D(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return np.asarray(X, dtype=object).ravel()\n",
    "Squeeze1D.__module__ = poly_mod_name\n",
    "setattr(poly_mod, \"Squeeze1D\", Squeeze1D)\n",
    "\n",
    "class TextStatExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_ = np.array([\"char_len\",\"word_count\",\"avg_word_len\"])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=object).ravel().tolist()\n",
    "        rows = []\n",
    "        for t in X:\n",
    "            t = t if isinstance(t, str) else \"\"\n",
    "            words = re.findall(r\"\\w+\", t, flags=re.UNICODE)\n",
    "            rows.append([len(t), len(words), (sum(len(w) for w in words)/len(words) if words else 0.0)])\n",
    "        return np.array(rows, dtype=float)\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array([\"char_len\",\"word_count\",\"avg_word_len\"])\n",
    "TextStatExtractor.__module__ = poly_mod_name\n",
    "setattr(poly_mod, \"TextStatExtractor\", TextStatExtractor)\n",
    "\n",
    "class AudioFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, sr=16000, n_mfcc=13):\n",
    "        self.sr = sr; self.n_mfcc = n_mfcc\n",
    "        self.feature_names_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        names = [\"dur_sec\",\"rms_mean\",\"rms_std\",\"zcr_mean\",\"spec_cent_mean\",\"spec_cent_std\"]\n",
    "        names += [f\"mfcc{i+1}_mean\" for i in range(self.n_mfcc)]\n",
    "        names += [f\"mfcc{i+1}_std\" for i in range(self.n_mfcc)]\n",
    "        self.feature_names_ = names\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=object).ravel().tolist()\n",
    "        feats = []\n",
    "        for p in X:\n",
    "            feats.append(self._feat_one(p))\n",
    "        return np.array(feats)\n",
    "    def _feat_one(self, path):\n",
    "        try:\n",
    "            y, sr = robust_load_wav(path, sr=self.sr)\n",
    "            if y is None or len(y)==0:\n",
    "                raise RuntimeError\n",
    "            dur = len(y) / float(sr)\n",
    "            rms = librosa.feature.rms(y=y).flatten()\n",
    "            zcr = librosa.feature.zero_crossing_rate(y).flatten()\n",
    "            sc  = librosa.feature.spectral_centroid(y=y, sr=sr).flatten()\n",
    "            mf  = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
    "            v = [\n",
    "                dur,\n",
    "                float(np.mean(rms)) if rms.size else 0.0,\n",
    "                float(np.std(rms))  if rms.size else 0.0,\n",
    "                float(np.mean(zcr)) if zcr.size else 0.0,\n",
    "                float(np.mean(sc))  if sc.size else 0.0,\n",
    "                float(np.std(sc))   if sc.size else 0.0,\n",
    "            ]\n",
    "            if mf.size:\n",
    "                v += list(np.mean(mf, axis=1)); v += list(np.std(mf, axis=1))\n",
    "            else:\n",
    "                v += [0.0]*self.n_mfcc + [0.0]*self.n_mfcc\n",
    "            return v\n",
    "        except Exception:\n",
    "            return [0.0]*(6 + self.n_mfcc*2)\n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return np.array(self.feature_names_ or [])\n",
    "AudioFeatureExtractor.__module__ = poly_mod_name\n",
    "setattr(poly_mod, \"AudioFeatureExtractor\", AudioFeatureExtractor)\n",
    "\n",
    "# ---------- Build inputs ----------\n",
    "def build_dataframe(audio_dir, text_dir, csv_path):\n",
    "    audio_map = list_basenames(audio_dir, (\"*.wav\",\"*.WAV\"))\n",
    "    text_map  = {}\n",
    "    for pat in (\"*.txt\",\"*.TXT\"):\n",
    "        for p in glob.glob(os.path.join(text_dir, pat)):\n",
    "            text_map[os.path.splitext(os.path.basename(p))[0]] = p\n",
    "\n",
    "    df_csv = try_read_csv(csv_path) if os.path.isfile(csv_path) else pd.DataFrame()\n",
    "    if not df_csv.empty:\n",
    "        fname_col = next((c for c in [\"filename\",\"file\",\"path\",\"wav\",\"audio\",\"fname\",\"id\",\"ID\",\"Name\",\"name\",\"Audio\"] if c in df_csv.columns), None)\n",
    "        if fname_col:\n",
    "            df_csv[\"basename\"] = df_csv[fname_col].astype(str).apply(lambda p: os.path.splitext(os.path.basename(p))[0])\n",
    "        elif \"basename\" not in df_csv.columns:\n",
    "            df_csv[\"basename\"] = df_csv.index.astype(str)\n",
    "    else:\n",
    "        union = sorted(set(audio_map.keys()))\n",
    "        df_csv = pd.DataFrame({\"basename\": union})\n",
    "\n",
    "    # attach paths + text\n",
    "    df_csv[\"audio_path\"] = df_csv[\"basename\"].map(audio_map)\n",
    "    # text value: prefer CSV text column, else .txt file\n",
    "    text_col = next((c for c in POSSIBLE_TEXT_COLS if c in df_csv.columns), None)\n",
    "    if text_col:\n",
    "        df_csv[\"text_value\"] = df_csv[text_col].fillna(\"\").astype(str)\n",
    "    else:\n",
    "        df_csv[\"text_value\"] = \"\"\n",
    "\n",
    "    def fill_from_txt(row):\n",
    "        if row[\"text_value\"]:\n",
    "            return row[\"text_value\"]\n",
    "        tp = text_map.get(row[\"basename\"])\n",
    "        return safe_read_txt(tp) if tp else \"\"\n",
    "    df_csv[\"text_value\"] = df_csv.apply(fill_from_txt, axis=1)\n",
    "\n",
    "    # keep rows with audio_path\n",
    "    df = df_csv[df_csv[\"audio_path\"].notna()].reset_index(drop=True)\n",
    "\n",
    "    # X_frame for model\n",
    "    X_frame = pd.DataFrame({\n",
    "        \"audio_path\": df[\"audio_path\"].astype(str).values,\n",
    "        \"text_value\": df[\"text_value\"].astype(str).values\n",
    "    })\n",
    "    return df, X_frame\n",
    "\n",
    "# ---------- Prediction core ----------\n",
    "def run_prediction(model_path, audio_dir, text_dir, csv_path, out_dir):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    # load model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # prepare data\n",
    "    df_meta, X_frame = build_dataframe(audio_dir, text_dir, csv_path)\n",
    "    if X_frame.empty:\n",
    "        raise SystemExit(\"No audio found to predict on.\")\n",
    "\n",
    "    # predict\n",
    "    preds = None\n",
    "    proba = None\n",
    "    details = {}\n",
    "\n",
    "    # determine if supervised ('model' step) or unsupervised ('cluster' step)\n",
    "    final_step_name, final_step = list(model.named_steps.items())[-1]\n",
    "    if final_step_name == \"model\":\n",
    "        preds = model.predict(X_frame)\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            proba = model.predict_proba(X_frame)  # shape (n, n_classes)\n",
    "            classes_ = getattr(final_step, \"classes_\", None)\n",
    "            details[\"classes_\"] = classes_.tolist() if classes_ is not None else None\n",
    "    elif final_step_name == \"cluster\":\n",
    "        preds = model.predict(X_frame)  # cluster index\n",
    "        # optional distances if available\n",
    "        if hasattr(final_step, \"transform\"):\n",
    "            distances = final_step.transform(model.named_steps[\"features\"].transform(X_frame))\n",
    "            details[\"cluster_distances_shape\"] = list(distances.shape)\n",
    "    else:\n",
    "        # generic fallback\n",
    "        preds = model.predict(X_frame)\n",
    "\n",
    "    # assemble output table\n",
    "    out = df_meta.copy()\n",
    "    out.insert(len(out.columns), \"prediction\", preds)\n",
    "\n",
    "    # add probabilities per class if available (supervised)\n",
    "    if proba is not None:\n",
    "        classes = details.get(\"classes_\")\n",
    "        if classes is None:\n",
    "            classes = list(range(proba.shape[1]))\n",
    "        for i, cls in enumerate(classes):\n",
    "            col = f\"proba_{cls}\"\n",
    "            out[col] = proba[:, i]\n",
    "\n",
    "    # save CSV\n",
    "    csv_out = os.path.join(out_dir, \"polyglot_predictions.csv\")\n",
    "    out.to_csv(csv_out, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    # summarize\n",
    "    summary = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"model_path\": model_path,\n",
    "        \"audio_dir\": audio_dir,\n",
    "        \"text_dir\": text_dir,\n",
    "        \"csv_path\": csv_path if os.path.isfile(csv_path) else None,\n",
    "        \"n_rows\": int(out.shape[0]),\n",
    "        \"prediction_column\": \"prediction\",\n",
    "        \"unique_predictions\": out[\"prediction\"].value_counts(dropna=False).to_dict(),\n",
    "        \"probabilities_included\": proba is not None,\n",
    "        \"details\": details\n",
    "    }\n",
    "    js_path = os.path.join(out_dir, \"polyglot_summary.json\")\n",
    "    with open(js_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(summary, f, indent=2)\n",
    "\n",
    "    # print a tiny preview\n",
    "    print(\"\\n=== Prediction complete ===\")\n",
    "    print(\"Predictions CSV ->\", csv_out)\n",
    "    print(\"Summary JSON    ->\", js_path)\n",
    "    print(\"Head:\")\n",
    "    print(out.head(10).to_string(index=False))\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser(description=\"PolyGlotAI batch prediction\")\n",
    "    ap.add_argument(\"--model\", default=DEFAULT_MODEL, help=\"Path to polyglot_model.pkl\")\n",
    "    ap.add_argument(\"--audio\", default=DEFAULT_AUDIO_DIR, help=\"Audio dir with .wav\")\n",
    "    ap.add_argument(\"--text\",  default=DEFAULT_TEXT_DIR,  help=\"Text dir with .txt (optional)\")\n",
    "    ap.add_argument(\"--csv\",   default=DEFAULT_CSV_PATH,  help=\"CSV metadata (optional but recommended)\")\n",
    "    ap.add_argument(\"--out\",   default=DEFAULT_OUT_DIR,   help=\"Output directory\")\n",
    "    args, _ = ap.parse_known_args()\n",
    "\n",
    "    run_prediction(args.model, args.audio, args.text, args.csv, args.out)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0d4cad-634d-4723-9541-84a5f12feff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
