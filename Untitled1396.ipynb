{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0cd66f5-df17-480d-9c0d-f19f5d6e4a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WARN] No label column found. Need ground truth to compute accuracy & heatmap.\n",
      "Searched for: ['label', 'Label', 'target', 'Target', 'accent', 'Accent', 'speaker_id', 'Speaker', 'class', 'Class']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import glob\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -------- Defaults --------\n",
    "DEFAULT_AUDIO_DIR = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\audio\"\n",
    "DEFAULT_TEXT_DIR  = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\text\"\n",
    "DEFAULT_CSV_PATH  = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\\archive\\British English Speech Recognition.csv\"\n",
    "DEFAULT_OUT_DIR   = r\"C:\\Users\\sagni\\Downloads\\Poly Glot AI\"\n",
    "\n",
    "POSSIBLE_LABELS = [\n",
    "    \"label\", \"Label\", \"target\", \"Target\", \"accent\", \"Accent\",\n",
    "    \"speaker_id\", \"Speaker\", \"class\", \"Class\"\n",
    "]\n",
    "POSSIBLE_TEXT_COLS = [\"transcript\", \"Transcript\", \"text\", \"Text\", \"utterance\", \"sentence\", \"phrase\"]\n",
    "\n",
    "\n",
    "# -------- Pickle-safe, lambda-free transformers --------\n",
    "class Squeeze1D(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X): return np.asarray(X, dtype=object).ravel()\n",
    "\n",
    "class TextStatExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.feature_names_ = np.array([\"char_len\", \"word_count\", \"avg_word_len\"])\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=object).ravel().tolist()\n",
    "        rows = []\n",
    "        for t in X:\n",
    "            t = t if isinstance(t, str) else \"\"\n",
    "            chars = len(t)\n",
    "            words = re.findall(r\"\\w+\", t, flags=re.UNICODE)\n",
    "            wcnt = len(words)\n",
    "            avgw = (sum(len(w) for w in words) / wcnt) if wcnt else 0.0\n",
    "            rows.append([chars, wcnt, avgw])\n",
    "        return np.array(rows, dtype=float)\n",
    "\n",
    "class AudioFeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"duration, rms mean/std, zcr mean, spectral centroid mean/std, 13 MFCC means + stds\"\"\"\n",
    "    def __init__(self, sr=16000, n_mfcc=13):\n",
    "        self.sr = sr\n",
    "        self.n_mfcc = n_mfcc\n",
    "    def fit(self, X, y=None): return self\n",
    "    def transform(self, X):\n",
    "        X = np.asarray(X, dtype=object).ravel().tolist()\n",
    "        feats = []\n",
    "        for p in X:\n",
    "            vec = self._feat_one(p)\n",
    "            feats.append(vec)\n",
    "        return np.array(feats)\n",
    "    def _feat_one(self, path):\n",
    "        try:\n",
    "            y, sr = robust_load_wav(path, sr=self.sr)\n",
    "            if y is None or len(y) == 0:\n",
    "                raise RuntimeError(\"audio load failed\")\n",
    "            dur = len(y) / float(sr)\n",
    "            rms = librosa.feature.rms(y=y).flatten()\n",
    "            zcr = librosa.feature.zero_crossing_rate(y).flatten()\n",
    "            sc  = librosa.feature.spectral_centroid(y=y, sr=sr).flatten()\n",
    "            mf  = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=self.n_mfcc)\n",
    "            v = [\n",
    "                dur,\n",
    "                float(np.mean(rms)) if rms.size else 0.0,\n",
    "                float(np.std(rms))  if rms.size else 0.0,\n",
    "                float(np.mean(zcr)) if zcr.size else 0.0,\n",
    "                float(np.mean(sc))  if sc.size else 0.0,\n",
    "                float(np.std(sc))   if sc.size else 0.0,\n",
    "            ]\n",
    "            if mf.size:\n",
    "                v += list(np.mean(mf, axis=1))\n",
    "                v += list(np.std(mf, axis=1))\n",
    "            else:\n",
    "                v += [0.0]*self.n_mfcc + [0.0]*self.n_mfcc\n",
    "            return v\n",
    "        except Exception:\n",
    "            return [0.0]*(6 + self.n_mfcc*2)\n",
    "\n",
    "def robust_load_wav(path, sr=16000):\n",
    "    try:\n",
    "        y, r = sf.read(path, always_2d=False)\n",
    "        if isinstance(y, np.ndarray):\n",
    "            if y.ndim > 1:\n",
    "                y = np.mean(y, axis=1)\n",
    "            if r != sr:\n",
    "                y = librosa.resample(y.astype(float), orig_sr=r, target_sr=sr)\n",
    "                r = sr\n",
    "        return y.astype(float), r\n",
    "    except Exception:\n",
    "        try:\n",
    "            y, r = librosa.load(path, sr=sr, mono=True)\n",
    "            return y, r\n",
    "        except Exception:\n",
    "            return None, None\n",
    "\n",
    "\n",
    "# -------- Helpers --------\n",
    "def list_basenames(root, exts):\n",
    "    out = {}\n",
    "    for pat in exts:\n",
    "        for path in glob.glob(os.path.join(root, pat)):\n",
    "            out[os.path.splitext(os.path.basename(path))[0]] = path\n",
    "    return out\n",
    "\n",
    "def read_csv_any(path):\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except Exception:\n",
    "        return pd.read_csv(path, encoding=\"latin-1\")\n",
    "\n",
    "\n",
    "# -------- Main --------\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(description=\"PolyGlotAI accuracy + heatmap\")\n",
    "    parser.add_argument(\"--audio\", default=DEFAULT_AUDIO_DIR)\n",
    "    parser.add_argument(\"--text\",  default=DEFAULT_TEXT_DIR)\n",
    "    parser.add_argument(\"--csv\",   default=DEFAULT_CSV_PATH)\n",
    "    parser.add_argument(\"--out\",   default=DEFAULT_OUT_DIR)\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    os.makedirs(args.out, exist_ok=True)\n",
    "\n",
    "    audio_map = list_basenames(args.audio, (\"*.wav\",\"*.WAV\"))\n",
    "    text_map  = list_basenames(args.text,  (\"*.txt\",\"*.TXT\"))\n",
    "\n",
    "    df_csv = read_csv_any(args.csv) if os.path.isfile(args.csv) else pd.DataFrame()\n",
    "    if not df_csv.empty:\n",
    "        fname_col = next((c for c in [\"filename\",\"file\",\"path\",\"wav\",\"audio\",\"fname\",\"id\",\"ID\",\"Name\",\"name\"] if c in df_csv.columns), None)\n",
    "        if fname_col:\n",
    "            df_csv[\"basename\"] = df_csv[fname_col].astype(str).apply(lambda p: os.path.splitext(os.path.basename(p))[0])\n",
    "        else:\n",
    "            df_csv[\"basename\"] = df_csv.index.astype(str)\n",
    "        text_col  = next((c for c in POSSIBLE_TEXT_COLS if c in df_csv.columns), None)\n",
    "        label_col = next((c for c in POSSIBLE_LABELS if c in df_csv.columns), None)\n",
    "    else:\n",
    "        union = sorted(set(audio_map.keys()) | set(text_map.keys()))\n",
    "        df_csv = pd.DataFrame({\"basename\": union})\n",
    "        text_col, label_col = None, None\n",
    "\n",
    "    # Attach paths + text\n",
    "    df_csv[\"audio_path\"] = df_csv[\"basename\"].map(audio_map)\n",
    "    df_csv[\"text_value\"] = \"\"\n",
    "    if text_col:\n",
    "        df_csv[\"text_value\"] = df_csv[text_col].fillna(\"\").astype(str)\n",
    "    # fill from .txt folder if empty\n",
    "    def fill_txt(row):\n",
    "        if row[\"text_value\"]:\n",
    "            return row[\"text_value\"]\n",
    "        p = text_map.get(row[\"basename\"])\n",
    "        if p and os.path.isfile(p):\n",
    "            try:\n",
    "                return open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\").read().strip()\n",
    "            except Exception:\n",
    "                return \"\"\n",
    "        return \"\"\n",
    "    df_csv[\"text_value\"] = df_csv.apply(fill_txt, axis=1)\n",
    "\n",
    "    # Keep rows with audio\n",
    "    df = df_csv[df_csv[\"audio_path\"].notna()].reset_index(drop=True)\n",
    "\n",
    "    # Labels?\n",
    "    if label_col and label_col in df.columns:\n",
    "        y_series = df[label_col]\n",
    "        if y_series.dtype == object:\n",
    "            cats = {v: i for i, v in enumerate(sorted(y_series.dropna().unique()))}\n",
    "            y = y_series.map(cats)\n",
    "        else:\n",
    "            y = y_series.copy()\n",
    "    else:\n",
    "        print(\"[WARN] No label column found. Need ground truth to compute accuracy & heatmap.\")\n",
    "        print(\"Searched for:\", POSSIBLE_LABELS)\n",
    "        return\n",
    "\n",
    "    # Build feature table\n",
    "    X_frame = pd.DataFrame({\n",
    "        \"audio_path\": df[\"audio_path\"].astype(str).values,\n",
    "        \"text_value\": df[\"text_value\"].astype(str).values\n",
    "    })\n",
    "\n",
    "    # Feature pipelines\n",
    "    audio_pipe = Pipeline([\n",
    "        (\"sel\", Squeeze1D()),\n",
    "        (\"afe\", AudioFeatureExtractor(sr=16000, n_mfcc=13)),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "    text_stats = TextStatExtractor()\n",
    "    text_tfidf = TfidfVectorizer(analyzer=\"char\", ngram_range=(2,4), max_features=800)\n",
    "    text_features = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"tfidf\", Pipeline([(\"sel\", Squeeze1D()), (\"tfidf\", text_tfidf)]), \"text_value\"),\n",
    "            (\"tstats\", Pipeline([(\"sel\", Squeeze1D()), (\"tstat\", text_stats)]), \"text_value\"),\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "    full_feat = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"audio\", audio_pipe, [\"audio_path\"]),\n",
    "            (\"text\",  text_features, [\"text_value\"])\n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "    # Train/test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_frame, y, test_size=0.25, random_state=42, stratify=y\n",
    "    )\n",
    "\n",
    "    models = {\n",
    "        \"LogisticRegression\": LogisticRegression(max_iter=2000),\n",
    "        \"RandomForest\": RandomForestClassifier(n_estimators=400, random_state=42, n_jobs=-1)\n",
    "    }\n",
    "\n",
    "    metrics = {}\n",
    "    best_name, best_score, best_pipe = None, -np.inf, None\n",
    "\n",
    "    for name, est in models.items():\n",
    "        pipe = Pipeline([(\"features\", full_feat), (\"model\", est)])\n",
    "        pipe.fit(X_train, y_train)\n",
    "        y_pred = pipe.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "        auc = None\n",
    "        try:\n",
    "            if len(np.unique(y_test)) == 2 and hasattr(pipe, \"predict_proba\"):\n",
    "                probs = pipe.predict_proba(X_test)[:, 1]\n",
    "                if not np.allclose(np.min(probs), np.max(probs)):\n",
    "                    auc = roc_auc_score(y_test, probs)\n",
    "        except Exception:\n",
    "            auc = None\n",
    "\n",
    "        chosen = auc if auc is not None else acc\n",
    "        metrics[name] = {\"accuracy\": float(acc), \"roc_auc\": (None if auc is None else float(auc)), \"chosen_score\": float(chosen)}\n",
    "        if chosen > best_score:\n",
    "            best_score, best_name, best_pipe = chosen, name, pipe\n",
    "\n",
    "    # ---- Accuracy bar chart ----\n",
    "    acc_path = os.path.join(args.out, \"polyglot_accuracy.png\")\n",
    "    names = list(metrics.keys())\n",
    "    accs  = [metrics[k][\"accuracy\"] for k in names]\n",
    "\n",
    "    plt.figure(figsize=(7,5), dpi=140)\n",
    "    bars = plt.bar(names, accs)\n",
    "    plt.title(\"Model Accuracy (Test Set)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.ylim(0, 1.0)\n",
    "    for b, v in zip(bars, accs):\n",
    "        plt.text(b.get_x() + b.get_width()/2, v + 0.01, f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(acc_path)\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Confusion matrix heatmap (best model) ----\n",
    "    y_pred_best = best_pipe.predict(X_test)\n",
    "    labels_sorted = np.unique(np.concatenate([y_test, y_pred_best]))\n",
    "    cm = confusion_matrix(y_test, y_pred_best, labels=labels_sorted)\n",
    "\n",
    "    heat_path = os.path.join(args.out, \"polyglot_confusion_heatmap.png\")\n",
    "    plt.figure(figsize=(6,5), dpi=140)\n",
    "    im = plt.imshow(cm, interpolation=\"nearest\")\n",
    "    plt.title(f\"Confusion Matrix (Best: {best_name})\")\n",
    "    plt.colorbar(im, fraction=0.046, pad=0.04)\n",
    "    ticks = np.arange(len(labels_sorted))\n",
    "    plt.xticks(ticks, labels_sorted)\n",
    "    plt.yticks(ticks, labels_sorted)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "\n",
    "    thresh = cm.max()/2.0 if cm.size else 0.5\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], \"d\"),\n",
    "                     ha=\"center\", va=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(heat_path)\n",
    "    plt.show()\n",
    "\n",
    "    # ---- Save metrics JSON ----\n",
    "    metrics_path = os.path.join(args.out, \"polyglot_metrics.json\")\n",
    "    out_metrics = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"audio_dir\": args.audio,\n",
    "        \"text_dir\": args.text,\n",
    "        \"csv_path\": args.csv,\n",
    "        \"models\": metrics,\n",
    "        \"best_model\": best_name,\n",
    "        \"labels\": [int(x) if isinstance(x, (np.integer,)) else (x.item() if isinstance(x, np.generic) else x) for x in labels_sorted]\n",
    "    }\n",
    "    with open(metrics_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(out_metrics, f, indent=2)\n",
    "\n",
    "    print(\"\\n=== Saved ===\")\n",
    "    print(\"Accuracy chart ->\", acc_path)\n",
    "    print(\"Heatmap        ->\", heat_path)\n",
    "    print(\"Metrics JSON   ->\", metrics_path)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf59dc8-9621-42f6-b675-a3311aa929e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
